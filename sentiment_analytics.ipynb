{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9ce9a2d-4648-4ce6-8d8b-3d0099b7362b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Notebook for sentiment analytics on text\n",
    "Initial Version 1.0\n",
    "\n",
    "Author: Ananth\n",
    "\n",
    "Comments: initial sentiment analtics are created on text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3395b1b-5860-439c-a319-582409c5aab9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install azure-ai-textanalytics\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "credential = AzureKeyCredential(\"6d9c9980908e4125943f868ccfbb905a\")\n",
    "endpoint=\"https://bcp-textanalytics.cognitiveservices.azure.com/\"\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint, credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4960ffa9-cec3-4d80-9efa-a01b5ca2e15f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_db = \"raw\"\n",
    "source_type = \"txt\"\n",
    "source_object_name = \"Speach_Text\"\n",
    "target_object_name = \"sentiment_analytics\"\n",
    "target_db = \"curated\"\n",
    "target_type = \"txt\"\n",
    "documents=[\"\"]\n",
    "\n",
    "def read_file(path):\n",
    "    return spark.read.csv(path)\n",
    " \n",
    "path=\"dbfs:/mnt/\"+source_db+\"/\"+source_object_name+\".\"+source_type\n",
    "outputpath = f\"dbfs:/mnt/{target_db}/sentiment_analytics.txt\"\n",
    "\n",
    "documents=read_file(path)\n",
    "documents=documents.select('_c0','_c1').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "response = text_analytics_client.analyze_sentiment(documents, language=\"en\")\n",
    "result = [doc for doc in response if not doc.is_error]\n",
    "\n",
    "str_list = [str(item) for item in result]\n",
    "conv_string = ' '.join(str_list)\n",
    "dbutils.fs.put(outputpath,conv_string,overwrite=True)\n",
    "\n",
    "#for doc in result:\n",
    "    # print(f\"Overall sentiment: {doc.sentiment}\")\n",
    "    # print(\n",
    "    #     f\"Scores: positive={doc.confidence_scores.positive}; \"\n",
    "    #     f\"neutral={doc.confidence_scores.neutral}; \"\n",
    "    #     f\"negative={doc.confidence_scores.negative}\\n\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06bd6fc0-7a9a-426e-8392-a10a12ecb613",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sentiment_analytics",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
