{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a4e9814-a3b2-4d76-90ef-e0a1bf063c56",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Notebook for Analtytics on Text\n",
    "Initial Version 1.0\n",
    "\n",
    "Author: Abhishek\n",
    "\n",
    "Comments: initial text analtics was created for Sentiment,Entity and PII data on text files manually generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c745a81-d1df-4754-ba55-524608c6bada",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install azure-ai-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c5dd0ca-c8f6-4287-964a-92cf89f80463",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "credential = AzureKeyCredential(\"\")\n",
    "endpoint=\"\"\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint, credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a84f6af1-b841-4cd3-88fe-b9ed769dd24f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Below is the code to perform Sentiment Analytics on text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf0b4b4d-f3aa-49cd-8f4a-cd1f76699038",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_db = \"raw\"\n",
    "source_type = \"txt\"\n",
    "source_object_name = \"Speach_Text\"\n",
    "target_object_name = \"Text_Analytics\"\n",
    "target_type = \"txt\"\n",
    "documents=[\"\"]\n",
    "\n",
    "def read_file(path):\n",
    "    return spark.read.csv(path)\n",
    " \n",
    "\n",
    "path=\"dbfs:/mnt/\"+source_db+\"/\"+source_object_name+\".\"+source_type\n",
    "documents=read_file(path)\n",
    "#print(type(documents))\n",
    "documents=documents.select('_c0','_c1').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "#display(documents)\n",
    "response = text_analytics_client.analyze_sentiment(documents, language=\"en\")\n",
    "result = [doc for doc in response if not doc.is_error]\n",
    "\n",
    "for doc in result:\n",
    "    print(f\"Overall sentiment: {doc.sentiment}\")\n",
    "    print(\n",
    "        f\"Scores: positive={doc.confidence_scores.positive}; \"\n",
    "        f\"neutral={doc.confidence_scores.neutral}; \"\n",
    "        f\"negative={doc.confidence_scores.negative}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9c2568a-cc37-4124-ba18-81e444612595",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Below is the code to perform Entity Analytics on text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fb9ecc0-c786-4c11-83d4-902ad8c4e6e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_db = \"raw\"\n",
    "source_type = \"txt\"\n",
    "source_object_name = \"Text_Analytics_Entity\"\n",
    "target_object_name = \"\"\n",
    "target_type = \"txt\"\n",
    "documents_entity=[\"\"]\n",
    "\n",
    "def read_file(path):\n",
    "    return spark.read.csv(path)\n",
    " \n",
    "path=\"dbfs:/mnt/\"+source_db+\"/\"+source_object_name+\".\"+source_type\n",
    "documents_entity=read_file(path)\n",
    "#print(type(documents))\n",
    "documents_entity=documents_entity.select('_c0').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "response = text_analytics_client.recognize_entities(documents_entity, language=\"en\")\n",
    "result = [doc for doc in response if not doc.is_error]\n",
    "\n",
    "for doc in result:\n",
    "    for entity in doc.entities:\n",
    "        print(f\"Entity: {entity.text}\")\n",
    "        print(f\"...Category: {entity.category}\")\n",
    "        print(f\"...Confidence Score: {entity.confidence_score}\")\n",
    "        print(f\"...Offset: {entity.offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "167aa9e8-c8c5-44a9-9a7c-21ac491472c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Recognize and categorize the PII data in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53b1d64c-78d9-4bd7-b640-fbddc573872d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_db = \"raw\"\n",
    "source_type = \"txt\"\n",
    "source_object_name = \"Text_Analytics_PII\"\n",
    "target_object_name = \"\"\n",
    "target_type = \"txt\"\n",
    "documents_pii=[\"\"]\n",
    "\n",
    "def read_file(path):\n",
    "    return spark.read.csv(path)\n",
    " \n",
    "path=\"dbfs:/mnt/\"+source_db+\"/\"+source_object_name+\".\"+source_type\n",
    "documents_pii=read_file(path)\n",
    "documents_pii=documents_pii.select('_c0').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "response = text_analytics_client.recognize_pii_entities(documents_pii, language=\"en\")\n",
    "result = [doc for doc in response if not doc.is_error]\n",
    "for idx, doc in enumerate(result):\n",
    "    print(f\"Document text: {documents[idx]}\")\n",
    "    print(f\"Redacted document text: {doc.redacted_text}\")\n",
    "    for entity in doc.entities:\n",
    "        print(f\"...Entity: {entity.text}\")\n",
    "        print(f\"......Category: {entity.category}\")\n",
    "        print(f\"......Confidence Score: {entity.confidence_score}\")\n",
    "        print(f\"......Offset: {entity.offset}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cd5b3be-5fe4-4447-878f-20c2855d2e30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Extracting Key Phrases on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c28b249b-e293-41b1-b418-8500d3318d94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_db = \"raw\"\n",
    "source_type = \"txt\"\n",
    "source_object_name = \"Text_Analytics_Key_Phrases\"\n",
    "target_object_name = \"\"\n",
    "target_type = \"txt\"\n",
    "documents_Key_Phrase=[\"\"]\n",
    "\n",
    "def read_file(path):\n",
    "    return spark.read.csv(path)\n",
    " \n",
    "path=\"dbfs:/mnt/\"+source_db+\"/\"+source_object_name+\".\"+source_type\n",
    "documents_Key_Phrase=read_file(path)\n",
    "documents_Key_Phrase=documents_Key_Phrase.select('_c0').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "response = text_analytics_client.extract_key_phrases(documents, language=\"en\")\n",
    "result = [doc for doc in response if not doc.is_error]\n",
    "\n",
    "for doc in result:\n",
    "    print(doc.key_phrases)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Analytics_Sentiment_Entity_PII",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
